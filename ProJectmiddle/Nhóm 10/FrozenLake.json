{"paragraphs":[{"text":"%sh\npip install matplotlib\npip install numpy \npip install seaborn\npip install tqdm\npip install gymnasium==0.27.0\npip install gymnasium[toy_text]\n","user":"anonymous","dateUpdated":"2023-05-10T23:19:11+0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1683735551106_1553982140","id":"20230510-184701_5469670","dateCreated":"2023-05-10T23:19:11+0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:968"},{"text":"%pyspark\nfrom __future__ import annotations\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib.patches import Patch\nfrom tqdm import tqdm\nimport gymnasium as gym\n","user":"anonymous","dateUpdated":"2023-05-10T23:19:11+0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1683735551130_-855211358","id":"20230510-184707_14583151","dateCreated":"2023-05-10T23:19:11+0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:969"},{"text":"%pyspark\nenv = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\")","user":"anonymous","dateUpdated":"2023-05-10T23:19:11+0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1683735551134_-2032621559","id":"20230510-184720_1941723","dateCreated":"2023-05-10T23:19:11+0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:970"},{"text":"%pyspark\nclass FrozenLakeAgent:\n    def __init__(\n        self,\n        learning_rate: float,\n        initial_epsilon: float,\n        epsilon_decay: float,\n        final_epsilon: float,\n        discount_factor: float = 0.95,\n    ):\n        \"\"\"\n        Khởi tạo tác tử học tăng cường với Q-table (một dictionary rỗng chứa giá trị của các cặp hành động - trạng thái) \n        và các tham số:\n            learning_rate: Tỷ lệ học tập của tác tử\n            initial_epsilon: Giá trị epsilon ban đầu\n            epsilon_decay: Tỷ lệ giảm dần của epsilon\n            final_epsilon: Giá trị cuối cùng của epsilon\n            discount_factor: Hệ số chiết khấu, được sử dụng để xác định mức độ ảnh hưởng của các phần thưởng trong tương lai \n                            đối với quyết định hiện tại\n        \"\"\"\n        self.q_values = defaultdict(lambda: np.zeros(env.action_space.n))\n        self.lr = learning_rate\n        self.discount_factor = discount_factor\n        self.epsilon = initial_epsilon\n        self.epsilon_decay = epsilon_decay\n        self.final_epsilon = final_epsilon\n        self.training_error = []\n\n    def get_action(self, obs: int) -> int:\n        \"\"\"\n        Trả về hành động tốt nhất với tỷ lệ (1 - epsilon)\n        hoặc một hành động ngẫu nhiên với tỷ lệ epsilon để đảm bảo tính khám phá\n        \"\"\"\n        # với tỷ lệ epsilon trả về hành động ngẫu nhiên để khám phá môi trường\n        if np.random.random() < self.epsilon:\n            return env.action_space.sample()\n\n        # với tỷ lệ (1 - epsilon) thực hiện hành động tham lam (khai thác)\n        else:\n            return int(np.argmax(self.q_values[obs]))\n\n    def update(\n        self,\n        obs: int,\n        action: int,\n        reward: float,\n        terminated: bool,\n        next_obs: int,\n    ):\n         # cập nhật giá trị Q-value của cặp trạng thái - hành động\n        future_q_value = (not terminated) * np.max(self.q_values[next_obs])\n        temporal_difference = (\n            reward + self.discount_factor * future_q_value - self.q_values[obs][action]\n        )\n\n        self.q_values[obs][action] = (\n            self.q_values[obs][action] + self.lr * temporal_difference\n        )\n        self.training_error.append(temporal_difference)\n\n    def decay_epsilon(self):\n        self.epsilon = max(self.final_epsilon, self.epsilon - epsilon_decay)\n","user":"anonymous","dateUpdated":"2023-05-10T23:19:11+0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1683735551135_-142402452","id":"20230510-184730_31307266","dateCreated":"2023-05-10T23:19:11+0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:971"},{"title":"Bắt đầu training","text":"%pyspark\n\n#Các tham số\nlearning_rate = 0.01\nn_episodes = 1000\nstart_epsilon = 1.0\nepsilon_decay = start_epsilon / (n_episodes / 2)   # giảm khám phá, tăng khai thác theo thời gian\nfinal_epsilon = 0.1\n\nagent = FrozenLakeAgent(\n    learning_rate=learning_rate,\n    initial_epsilon=start_epsilon,\n    epsilon_decay=epsilon_decay,\n    final_epsilon=final_epsilon,\n)\n\nfrom IPython.display import clear_output\nenv = gym.wrappers.RecordEpisodeStatistics(env, deque_size=n_episodes)\nfor episode in tqdm(range(n_episodes)):\n    obs, info = env.reset()\n    done = False\n    clear_output()\n    list = []\n    # một vòng huấn luyện\n    while not done:\n        action = agent.get_action(obs)\n        next_obs, reward, terminated, truncated, info = env.step(action)\n        # cập nhật giá trị q-value\n        agent.update(obs, action, reward, terminated, next_obs)\n        # cập nhật trạng thái hiện tại và môi trường đã xong một vòng huấn luyện hay chưa\n        done = terminated or truncated\n        obs = next_obs\n        frame = env.render()\n        list.append(frame)\n        if(done == True and reward == 1):\n            for f in list:\n                plt.imshow(f)\n                plt.show()\n\n\n    agent.decay_epsilon()\n","user":"anonymous","dateUpdated":"2023-05-10T23:19:11+0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1683735551157_645589161","id":"20230510-184739_33383722","dateCreated":"2023-05-10T23:19:11+0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:972"},{"title":"Trực quan hoá dữ liệu từ training","text":"%pyspark\nrolling_length = 500\nfig, axs = plt.subplots(ncols=3, figsize=(12, 5))\naxs[0].set_title(\"Episode rewards\")\nreward_moving_average = (\n    np.convolve(\n        np.array(env.return_queue).flatten(), np.ones(rolling_length), mode=\"valid\"\n    )\n    / rolling_length\n)\naxs[0].plot(range(len(reward_moving_average)), reward_moving_average)\naxs[1].set_title(\"Episode lengths\")\nlength_moving_average = (\n    np.convolve(\n        np.array(env.length_queue).flatten(), np.ones(rolling_length), mode=\"same\"\n    )\n    / rolling_length\n)\naxs[1].plot(range(len(length_moving_average)), length_moving_average)\naxs[2].set_title(\"Training Error\")\ntraining_error_moving_average = (\n    np.convolve(np.array(agent.training_error), np.ones(rolling_length), mode=\"same\")\n    / rolling_length\n)\naxs[2].plot(range(len(training_error_moving_average)), training_error_moving_average)\nplt.tight_layout()\nplt.show()","user":"anonymous","dateUpdated":"2023-05-10T23:19:11+0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1683735551159_-1724704828","id":"20230510-184750_26208394","dateCreated":"2023-05-10T23:19:11+0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:973"}],"name":"FrozenLake","id":"2J189ZFN4","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}